

version: "3.9"

services:
  # ---------- Spark Master ----------
  spark-master:
    image: sonusukralia/v2_spark_mw:1.0
    container_name: spark-master
    hostname: spark-master
    user: root
    command: >
      bash -c "
      mkdir -p /opt/bitnami/spark/logs &&
      mkdir -p /opt/bitnami/spark/work &&
      find /opt/bitnami/spark/work -type d -mtime +7 -exec rm -rf {} \; 2>/dev/null || true &&
      find /opt/bitnami/spark/logs -name '*.out.*' -mtime +7 -delete 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/conf 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/logs 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/work 2>/dev/null || true &&
      /opt/bitnami/spark/sbin/start-master.sh \
      --webui-port 8080 \
      >> /opt/bitnami/spark/logs/master.out 2>&1
      "
    ports:
      - "9090:8080"
      - "7077:7077"
    environment:
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_WEBUI_PORT: "8080"
      SPARK_WORKER_WEBUI_PORT: "8081"
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_USER: "root"
      PYSPARK_PYTHON: /opt/bitnami/python/bin/python3
      SPARK_EVENTLOG_ENABLED: "true"
      SPARK_EVENTLOG_DIR: /opt/spark-events
      SPARK_HISTORY_FS_LOGDIRECTORY: /opt/spark-events
      SPARK_LOG_DIR: /opt/bitnami/spark/logs
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs
      - ./spark-events:/opt/spark-events
      - ./spark-logs/master:/opt/bitnami/spark/logs
      - ./spark-work:/opt/bitnami/spark/work
      - ./spark-conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Spark Worker ----------
  spark-worker:
    image: sonusukralia/v2_spark_mw:1.0
    container_name: spark-worker
    hostname: spark-worker
    user: root
    depends_on:
      - spark-master
    command: >
      bash -c "
      mkdir -p /opt/bitnami/spark/logs &&
      mkdir -p /opt/bitnami/spark/work &&
      find /opt/bitnami/spark/work -type d -mtime +7 -exec rm -rf {} \; 2>/dev/null || true &&
      find /opt/bitnami/spark/logs -name '*.out.*' -mtime +7 -delete 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/conf 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/logs 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/work 2>/dev/null || true &&
      exec /opt/bitnami/spark/sbin/start-worker.sh spark://spark-master:7077 \
      >> /opt/bitnami/spark/logs/worker.out 2>&1
      "
    ports:
      - "8081:8081"
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: "4"
      SPARK_WORKER_MEMORY: 4g
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_WEBUI_PORT: "8081"
      SPARK_WORKER_HOST: spark-worker
      SPARK_LOCAL_IP: spark-worker
      SPARK_WORKER_BIND_ADDRESS: 0.0.0.0
      SPARK_LOCAL_HOSTNAME: spark-worker
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_USER: "root"
      PYSPARK_PYTHON: /opt/bitnami/python/bin/python3
      SPARK_EVENTLOG_ENABLED: "true"
      SPARK_EVENTLOG_DIR: /opt/spark-events
      SPARK_HISTORY_FS_LOGDIRECTORY: /opt/spark-events
      SPARK_LOG_DIR: /opt/bitnami/spark/logs
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs
      - ./spark-events:/opt/spark-events
      - ./spark-logs/worker:/opt/bitnami/spark/logs
      - ./spark-work:/opt/bitnami/spark/work
      - ./spark-conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Spark History Server ----------
  spark-history-server:
    image: sonusukralia/v2_spark_mw:1.0
    container_name: spark-history-server
    user: root
    command: >
      bash -c "
      mkdir -p /opt/bitnami/spark/logs &&
      find /opt/bitnami/spark/logs -name '*.out.*' -mtime +7 -delete 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/conf 2>/dev/null || true &&
      chmod -R 777 /opt/bitnami/spark/logs 2>/dev/null || true &&
      chmod -R 777 /opt/spark-events 2>/dev/null || true &&
      exec /opt/bitnami/spark/sbin/start-history-server.sh \
      >> /opt/bitnami/spark/logs/history.out 2>&1
      "
    ports:
      - "18080:18080"
    environment:
      SPARK_HISTORY_OPTS: "-Dspark.history.fs.logDirectory=/opt/spark-events -Dspark.history.fs.update.interval=5s -Dspark.history.ui.maxApplications=100 -Dspark.ui.custom.executor.log.url=http://localhost:8081/logPage/?appId={{APP_ID}}&executorId={{EXECUTOR_ID}}&logType={{LOG_TYPE}}"
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_USER: "root"
      PYSPARK_PYTHON: /opt/bitnami/python/bin/python3
      SPARK_EVENTLOG_ENABLED: "true"
      SPARK_EVENTLOG_DIR: /opt/spark-events
      SPARK_HISTORY_FS_LOGDIRECTORY: /opt/spark-events
      SPARK_LOG_DIR: /opt/bitnami/spark/logs
    volumes:
      - ./spark-events:/opt/spark-events
      - ./spark-logs/history:/opt/bitnami/spark/logs
    depends_on:
      - spark-master
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Postgres ----------
  postgres:
    image: sonusukralia/v2_postgres:1.0
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - ./postgres:/var/lib/postgresql/data
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Airflow Scheduler ----------
  airflow-scheduler:
    image: sonusukralia/v2_airflow_spark:1.0
    container_name: airflow-scheduler
    user: root
    env_file:
      - airflow.env
    command: >
      bash -c "
      mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/jobs &&
      chmod -R 777 /opt/airflow/logs 2>/dev/null || true &&
      chmod -R 777 /opt/airflow/dags 2>/dev/null || true &&
      chmod -R 777 /opt/airflow/jobs 2>/dev/null || true &&
      airflow db migrate &&
      airflow users create --username admin --firstname Sonu --lastname Kumar --role Admin --email admin@example.com --password admin 2>/dev/null || true &&
      airflow scheduler
      "
    volumes:
      - ./jobs:/opt/airflow/jobs
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./spark-events:/opt/spark-events  # ADD THIS LINE
    depends_on:
      - postgres
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Airflow Webserver ----------
  airflow-webserver:
    image: sonusukralia/v2_airflow_spark:1.0
    container_name: airflow-webserver
    user: root
    env_file:
      - airflow.env
    command: >
      bash -c "
      mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/jobs &&
      chmod -R 777 /opt/airflow/logs 2>/dev/null || true &&
      chmod -R 777 /opt/airflow/dags 2>/dev/null || true &&
      chmod -R 777 /opt/airflow/jobs 2>/dev/null || true &&
      airflow webserver
      "
    ports:
      - "8085:8080"
    volumes:
      - ./jobs:/opt/airflow/jobs
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./spark-events:/opt/spark-events  # ADD THIS LINE
    depends_on:
      - postgres
      - airflow-scheduler
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- MinIO ----------
  minio:
    image: sonusukralia/v2_minio:1.0
    container_name: minio
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
      MINIO_REGION_NAME: us-east-1
      MINIO_REGION: us-east-1
    command: ["server", "/data", "--console-address", ":9001"]
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio:/data
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- MinIO Client ----------
  minio-mc:
    image: sonusukralia/v2_minio_client:1.0
    container_name: minio-mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO service to become ready...';
      until nc -z minio 9000; do
        echo '...waiting for MinIO port 9000...';
        sleep 2;
      done;
      echo 'MinIO port is open, giving extra time for storage initialization...';
      sleep 10;
      echo 'Connecting MinIO client...';
      /usr/bin/mc alias set minio http://minio:9000 admin password;
      /usr/bin/mc mb minio/warehouse || true;
      /usr/bin/mc mb minio/test || true;
      /usr/bin/mc policy set public minio/warehouse;
      /usr/bin/mc policy set public minio/test;
      echo 'âœ… MinIO client setup completed successfully.';
      tail -f /dev/null;
      "
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Jupyter ----------
  jupyter-spark:
    image: sonusukralia/v2_jupyter_spark:1.0
    container_name: jupyter-spark
    hostname: jupyter-spark
    user: root
    environment:
      SPARK_HOME: /opt/spark
      PYSPARK_PYTHON: python
      PYSPARK_DRIVER_PYTHON: python
      SPARK_MASTER: spark://spark-master:7077
      SPARK_DRIVER_BINDADDRESS: 0.0.0.0
      SPARK_DRIVER_HOST: jupyter-spark
      SPARK_DRIVER_PORT: "4041"
      SPARK_BLOCKMANAGER_PORT: "4042"
      SPARK_EVENTLOG_ENABLED: "true"
      SPARK_EVENTLOG_DIR: /opt/spark-events
    ports:
      - "8888:8888"
      - "4040:4040"
      - "4041:4041"
      - "4042:4042"
    volumes:
      - ./notebooks:/workspace
      - ./spark-events:/opt/spark-events
      - ./spark-logs/jupyter:/workspace/logs
      - ./spark-work:/opt/bitnami/spark/work
      - ./spark-conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
    depends_on:
      - spark-master
      - minio
      - postgres
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Nessie ----------
  nessie:
    image: sonusukralia/v2_nessie:1.0
    container_name: nessie
    ports:
      - "19120:19120"
    volumes:
      - ./nessie:/nessie
    networks:
      - data-platform-network
    restart: unless-stopped

  # ---------- Dremio ----------
  dremio:
    platform: linux/x86_64
    image: sonusukralia/v2_dremio:1.0
    container_name: dremio
    user: "0:0"
    ports:
      - "9047:9047"
      - "31010:31010"
      - "32010:32010"
    volumes:
      - ./dremio:/opt/dremio/data
    depends_on:
      - nessie
      - minio
    networks:
      - data-platform-network
    restart: unless-stopped

networks:
  data-platform-network:
    driver: bridge







