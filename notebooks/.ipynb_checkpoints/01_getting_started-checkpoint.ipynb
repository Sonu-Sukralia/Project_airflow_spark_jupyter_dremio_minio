{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Spark\n",
    "This notebook demonstrates basic Spark operations in the data platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GettingStarted\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"‚úÖ Spark {spark.version} session created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = [\n",
    "    (1, \"Alice\", 25, \"Engineering\"),\n",
    "    (2, \"Bob\", 30, \"Sales\"),\n",
    "    (3, \"Charlie\", 35, \"Engineering\"),\n",
    "    (4, \"Diana\", 28, \"Marketing\"),\n",
    "    (5, \"Eve\", 32, \"Engineering\")\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"age\", \"department\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"üìä Sample DataFrame:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations\n",
    "print(\"üìà Department Statistics:\")\n",
    "dept_stats = df.groupBy(\"department\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"count\"),\n",
    "        avg(\"age\").alias(\"avg_age\")\n",
    "    ) \\\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "\n",
    "dept_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter example\n",
    "print(\"üîç Engineering employees:\")\n",
    "engineering = df.filter(col(\"department\") == \"Engineering\")\n",
    "engineering.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to MinIO (S3)\n",
    "output_path = \"s3a://test/sample_data\"\n",
    "print(f\"üíæ Writing data to MinIO: {output_path}\")\n",
    "\n",
    "df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_path)\n",
    "\n",
    "print(\"‚úÖ Data written successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back from MinIO\n",
    "print(\"üìñ Reading data from MinIO...\")\n",
    "df_read = spark.read.parquet(output_path)\n",
    "df_read.show()\n",
    "print(\"‚úÖ Data read successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "spark.stop()\n",
    "print(\"üëã Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
