Spark Executor Command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx2048M" "-Dspark.driver.port=38263" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@f91dceacf835:38263" "--executor-id" "1" "--hostname" "spark-worker" "--cores" "2" "--app-id" "app-20251209222943-0000" "--worker-url" "spark://Worker@spark-worker:32783" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/12/09 22:29:44 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 144@spark-worker
25/12/09 22:29:44 INFO SignalUtils: Registering signal handler for TERM
25/12/09 22:29:44 INFO SignalUtils: Registering signal handler for HUP
25/12/09 22:29:44 INFO SignalUtils: Registering signal handler for INT
25/12/09 22:29:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/09 22:29:45 INFO SecurityManager: Changing view acls to: root
25/12/09 22:29:45 INFO SecurityManager: Changing modify acls to: root
25/12/09 22:29:45 INFO SecurityManager: Changing view acls groups to: 
25/12/09 22:29:45 INFO SecurityManager: Changing modify acls groups to: 
25/12/09 22:29:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
25/12/09 22:29:45 INFO TransportClientFactory: Successfully created connection to f91dceacf835/172.19.0.10:38263 after 99 ms (0 ms spent in bootstraps)
25/12/09 22:29:46 INFO SecurityManager: Changing view acls to: root
25/12/09 22:29:46 INFO SecurityManager: Changing modify acls to: root
25/12/09 22:29:46 INFO SecurityManager: Changing view acls groups to: 
25/12/09 22:29:46 INFO SecurityManager: Changing modify acls groups to: 
25/12/09 22:29:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
25/12/09 22:29:46 INFO TransportClientFactory: Successfully created connection to f91dceacf835/172.19.0.10:38263 after 3 ms (0 ms spent in bootstraps)
25/12/09 22:29:46 INFO DiskBlockManager: Created local directory at /tmp/spark-99f23499-ccf4-4e99-8a47-96195382b71c/executor-d5d66525-ef60-4556-b374-5fd5e528d295/blockmgr-8c819653-a82c-4797-9608-a0bd62303d37
25/12/09 22:29:46 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/12/09 22:29:46 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@f91dceacf835:38263
25/12/09 22:29:46 INFO WorkerWatcher: Connecting to worker spark://Worker@spark-worker:32783
25/12/09 22:29:46 INFO TransportClientFactory: Successfully created connection to spark-worker/172.19.0.7:32783 after 3 ms (0 ms spent in bootstraps)
25/12/09 22:29:46 INFO WorkerWatcher: Successfully connected to spark://Worker@spark-worker:32783
25/12/09 22:29:46 INFO ResourceUtils: ==============================================================
25/12/09 22:29:46 INFO ResourceUtils: No custom resources configured for spark.executor.
25/12/09 22:29:46 INFO ResourceUtils: ==============================================================
25/12/09 22:29:46 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
25/12/09 22:29:46 INFO Executor: Starting executor ID 1 on host spark-worker
25/12/09 22:29:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41965.
25/12/09 22:29:46 INFO NettyBlockTransferService: Server created on spark-worker:41965
25/12/09 22:29:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/12/09 22:29:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(1, spark-worker, 41965, None)
25/12/09 22:29:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(1, spark-worker, 41965, None)
25/12/09 22:29:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(1, spark-worker, 41965, None)
25/12/09 22:29:46 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/12/09 22:29:48 INFO CoarseGrainedExecutorBackend: Got assigned task 0
25/12/09 22:29:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/12/09 22:29:48 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:48 INFO TransportClientFactory: Successfully created connection to f91dceacf835/172.19.0.10:36903 after 5 ms (0 ms spent in bootstraps)
25/12/09 22:29:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 1048.8 MiB)
25/12/09 22:29:48 INFO TorrentBroadcast: Reading broadcast variable 1 took 168 ms
25/12/09 22:29:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.7 KiB, free 1048.8 MiB)
25/12/09 22:29:49 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:49 INFO CodeGenerator: Code generated in 215.425175 ms
25/12/09 22:29:49 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1048.7 MiB)
25/12/09 22:29:49 INFO TorrentBroadcast: Reading broadcast variable 0 took 26 ms
25/12/09 22:29:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 380.9 KiB, free 1048.4 MiB)
25/12/09 22:29:49 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
25/12/09 22:29:49 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
25/12/09 22:29:49 INFO MetricsSystemImpl: s3a-file-system metrics system started
25/12/09 22:29:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2128 bytes result sent to driver
25/12/09 22:29:53 INFO CoarseGrainedExecutorBackend: Got assigned task 2
25/12/09 22:29:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
25/12/09 22:29:53 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
25/12/09 22:29:53 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.4 MiB)
25/12/09 22:29:53 INFO TorrentBroadcast: Reading broadcast variable 4 took 18 ms
25/12/09 22:29:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.2 KiB, free 1048.4 MiB)
25/12/09 22:29:53 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
25/12/09 22:29:53 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@f91dceacf835:38263)
25/12/09 22:29:53 INFO MapOutputTrackerWorker: Got the map output locations
25/12/09 22:29:53 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 0 (0.0 B) local and 1 (60.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/12/09 22:29:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/12/09 22:29:53 INFO TransportClientFactory: Successfully created connection to spark-worker/172.19.0.7:43025 after 2 ms (0 ms spent in bootstraps)
25/12/09 22:29:53 INFO CodeGenerator: Code generated in 34.27727 ms
25/12/09 22:29:53 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 4038 bytes result sent to driver
25/12/09 22:29:55 INFO CoarseGrainedExecutorBackend: Got assigned task 7
25/12/09 22:29:55 INFO Executor: Running task 0.0 in stage 9.0 (TID 7)
25/12/09 22:29:55 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
25/12/09 22:29:55 INFO TorrentBroadcast: Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 1048.3 MiB)
25/12/09 22:29:55 INFO TorrentBroadcast: Reading broadcast variable 13 took 17 ms
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 23.0 KiB, free 1048.3 MiB)
25/12/09 22:29:55 INFO CodeGenerator: Code generated in 46.304003 ms
25/12/09 22:29:55 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:55 INFO CodeGenerator: Code generated in 19.906261 ms
25/12/09 22:29:55 INFO TorrentBroadcast: Started reading broadcast variable 12 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1048.3 MiB)
25/12/09 22:29:55 INFO TorrentBroadcast: Reading broadcast variable 12 took 23 ms
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 380.9 KiB, free 1047.9 MiB)
25/12/09 22:29:55 INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 1966 bytes result sent to driver
25/12/09 22:29:56 INFO CoarseGrainedExecutorBackend: Got assigned task 9
25/12/09 22:29:56 INFO Executor: Running task 0.0 in stage 12.0 (TID 9)
25/12/09 22:29:56 INFO MapOutputTrackerWorker: Updating epoch to 3 and clearing cache
25/12/09 22:29:56 INFO TorrentBroadcast: Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:56 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 79.5 KiB, free 1047.8 MiB)
25/12/09 22:29:56 INFO TorrentBroadcast: Reading broadcast variable 16 took 16 ms
25/12/09 22:29:56 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 218.7 KiB, free 1047.6 MiB)
25/12/09 22:29:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/12/09 22:29:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/12/09 22:29:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/12/09 22:29:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/12/09 22:29:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/12/09 22:29:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/12/09 22:29:56 INFO CodecConfig: Compression: SNAPPY
25/12/09 22:29:56 INFO CodecConfig: Compression: SNAPPY
25/12/09 22:29:56 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/12/09 22:29:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "amount",
    "type" : "long",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "id",
    "type" : "long",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "processing_timestamp",
    "type" : "timestamp",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "processing_date",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "processing_time",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "status",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "amount_category",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int64 amount;
  optional int64 id;
  required int96 processing_timestamp;
  required binary processing_date (STRING);
  required binary processing_time (STRING);
  required binary status (STRING);
  required binary amount_category (STRING);
}

       
25/12/09 22:29:56 INFO CodecPool: Got brand-new compressor [.snappy]
25/12/09 22:29:56 INFO CodeGenerator: Code generated in 16.072724 ms
25/12/09 22:29:56 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:56 INFO TorrentBroadcast: Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:56 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1048.1 MiB)
25/12/09 22:29:56 INFO TorrentBroadcast: Reading broadcast variable 15 took 16 ms
25/12/09 22:29:56 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 380.9 KiB, free 1047.7 MiB)
25/12/09 22:29:57 INFO FileOutputCommitter: Saved output of task 'attempt_202512092229566446705824045876556_0012_m_000000_9' to s3a://warehouse/processed/_temporary/0/task_202512092229566446705824045876556_0012_m_000000
25/12/09 22:29:57 INFO SparkHadoopMapRedUtil: attempt_202512092229566446705824045876556_0012_m_000000_9: Committed. Elapsed time: 147 ms.
25/12/09 22:29:57 INFO Executor: Finished task 0.0 in stage 12.0 (TID 9). 2613 bytes result sent to driver
25/12/09 22:29:57 INFO CoarseGrainedExecutorBackend: Got assigned task 10
25/12/09 22:29:57 INFO Executor: Running task 0.0 in stage 13.0 (TID 10)
25/12/09 22:29:57 INFO TorrentBroadcast: Started reading broadcast variable 18 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:57 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 1047.7 MiB)
25/12/09 22:29:57 INFO TorrentBroadcast: Reading broadcast variable 18 took 12 ms
25/12/09 22:29:57 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 15.6 KiB, free 1047.7 MiB)
25/12/09 22:29:57 INFO CodeGenerator: Code generated in 11.206465 ms
25/12/09 22:29:57 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:57 INFO CodeGenerator: Code generated in 7.851688 ms
25/12/09 22:29:57 INFO TorrentBroadcast: Started reading broadcast variable 17 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1047.6 MiB)
25/12/09 22:29:58 INFO TorrentBroadcast: Reading broadcast variable 17 took 17 ms
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 380.9 KiB, free 1047.3 MiB)
25/12/09 22:29:58 INFO Executor: Finished task 0.0 in stage 13.0 (TID 10). 1923 bytes result sent to driver
25/12/09 22:29:59 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
25/12/09 22:29:59 INFO MemoryStore: MemoryStore cleared
ver commanded a shutdown
