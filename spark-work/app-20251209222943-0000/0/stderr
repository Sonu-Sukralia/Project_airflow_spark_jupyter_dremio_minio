Spark Executor Command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx2048M" "-Dspark.driver.port=38263" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@f91dceacf835:38263" "--executor-id" "0" "--hostname" "spark-worker" "--cores" "2" "--app-id" "app-20251209222943-0000" "--worker-url" "spark://Worker@spark-worker:32783" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/12/09 22:29:44 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 143@spark-worker
25/12/09 22:29:44 INFO SignalUtils: Registering signal handler for TERM
25/12/09 22:29:44 INFO SignalUtils: Registering signal handler for HUP
25/12/09 22:29:44 INFO SignalUtils: Registering signal handler for INT
25/12/09 22:29:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/09 22:29:45 INFO SecurityManager: Changing view acls to: root
25/12/09 22:29:45 INFO SecurityManager: Changing modify acls to: root
25/12/09 22:29:45 INFO SecurityManager: Changing view acls groups to: 
25/12/09 22:29:45 INFO SecurityManager: Changing modify acls groups to: 
25/12/09 22:29:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
25/12/09 22:29:45 INFO TransportClientFactory: Successfully created connection to f91dceacf835/172.19.0.10:38263 after 89 ms (0 ms spent in bootstraps)
25/12/09 22:29:46 INFO SecurityManager: Changing view acls to: root
25/12/09 22:29:46 INFO SecurityManager: Changing modify acls to: root
25/12/09 22:29:46 INFO SecurityManager: Changing view acls groups to: 
25/12/09 22:29:46 INFO SecurityManager: Changing modify acls groups to: 
25/12/09 22:29:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
25/12/09 22:29:46 INFO TransportClientFactory: Successfully created connection to f91dceacf835/172.19.0.10:38263 after 3 ms (0 ms spent in bootstraps)
25/12/09 22:29:46 INFO DiskBlockManager: Created local directory at /tmp/spark-99f23499-ccf4-4e99-8a47-96195382b71c/executor-d5d66525-ef60-4556-b374-5fd5e528d295/blockmgr-45efb624-72af-4e1a-9ee8-bdf581ce5320
25/12/09 22:29:46 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/12/09 22:29:46 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@f91dceacf835:38263
25/12/09 22:29:46 INFO WorkerWatcher: Connecting to worker spark://Worker@spark-worker:32783
25/12/09 22:29:46 INFO TransportClientFactory: Successfully created connection to spark-worker/172.19.0.7:32783 after 3 ms (0 ms spent in bootstraps)
25/12/09 22:29:46 INFO WorkerWatcher: Successfully connected to spark://Worker@spark-worker:32783
25/12/09 22:29:46 INFO ResourceUtils: ==============================================================
25/12/09 22:29:46 INFO ResourceUtils: No custom resources configured for spark.executor.
25/12/09 22:29:46 INFO ResourceUtils: ==============================================================
25/12/09 22:29:46 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
25/12/09 22:29:46 INFO Executor: Starting executor ID 0 on host spark-worker
25/12/09 22:29:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43025.
25/12/09 22:29:46 INFO NettyBlockTransferService: Server created on spark-worker:43025
25/12/09 22:29:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/12/09 22:29:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, spark-worker, 43025, None)
25/12/09 22:29:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, spark-worker, 43025, None)
25/12/09 22:29:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, spark-worker, 43025, None)
25/12/09 22:29:46 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/12/09 22:29:51 INFO CoarseGrainedExecutorBackend: Got assigned task 1
25/12/09 22:29:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/12/09 22:29:51 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:51 INFO TransportClientFactory: Successfully created connection to f91dceacf835/172.19.0.10:36903 after 5 ms (0 ms spent in bootstraps)
25/12/09 22:29:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 1048.8 MiB)
25/12/09 22:29:51 INFO TorrentBroadcast: Reading broadcast variable 3 took 157 ms
25/12/09 22:29:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.6 KiB, free 1048.8 MiB)
25/12/09 22:29:52 INFO CodeGenerator: Code generated in 143.237653 ms
25/12/09 22:29:52 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:52 INFO CodeGenerator: Code generated in 13.136146 ms
25/12/09 22:29:52 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1048.7 MiB)
25/12/09 22:29:52 INFO TorrentBroadcast: Reading broadcast variable 2 took 23 ms
25/12/09 22:29:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 380.9 KiB, free 1048.4 MiB)
25/12/09 22:29:52 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
25/12/09 22:29:52 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
25/12/09 22:29:52 INFO MetricsSystemImpl: s3a-file-system metrics system started
25/12/09 22:29:53 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2009 bytes result sent to driver
25/12/09 22:29:54 INFO CoarseGrainedExecutorBackend: Got assigned task 3
25/12/09 22:29:54 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
25/12/09 22:29:54 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
25/12/09 22:29:54 INFO TorrentBroadcast: Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 1048.4 MiB)
25/12/09 22:29:54 INFO TorrentBroadcast: Reading broadcast variable 6 took 21 ms
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 13.5 KiB, free 1048.4 MiB)
25/12/09 22:29:54 INFO CodeGenerator: Code generated in 23.966745 ms
25/12/09 22:29:54 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:54 INFO CodeGenerator: Code generated in 12.542244 ms
25/12/09 22:29:54 INFO TorrentBroadcast: Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1048.3 MiB)
25/12/09 22:29:54 INFO TorrentBroadcast: Reading broadcast variable 5 took 17 ms
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 380.9 KiB, free 1047.9 MiB)
25/12/09 22:29:54 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 1656 bytes result sent to driver
25/12/09 22:29:54 INFO CoarseGrainedExecutorBackend: Got assigned task 4
25/12/09 22:29:54 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
25/12/09 22:29:54 INFO TorrentBroadcast: Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 1047.9 MiB)
25/12/09 22:29:54 INFO TorrentBroadcast: Reading broadcast variable 8 took 13 ms
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.6 KiB, free 1047.9 MiB)
25/12/09 22:29:54 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:54 INFO TorrentBroadcast: Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1047.9 MiB)
25/12/09 22:29:54 INFO TorrentBroadcast: Reading broadcast variable 7 took 14 ms
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 380.9 KiB, free 1047.5 MiB)
25/12/09 22:29:54 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 1966 bytes result sent to driver
25/12/09 22:29:54 INFO CoarseGrainedExecutorBackend: Got assigned task 5
25/12/09 22:29:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
25/12/09 22:29:54 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
25/12/09 22:29:54 INFO TorrentBroadcast: Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1047.5 MiB)
25/12/09 22:29:54 INFO TorrentBroadcast: Reading broadcast variable 9 took 19 ms
25/12/09 22:29:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.2 KiB, free 1047.5 MiB)
25/12/09 22:29:54 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
25/12/09 22:29:54 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@f91dceacf835:38263)
25/12/09 22:29:54 INFO MapOutputTrackerWorker: Got the map output locations
25/12/09 22:29:54 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/12/09 22:29:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
25/12/09 22:29:54 INFO CodeGenerator: Code generated in 22.223513 ms
25/12/09 22:29:54 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 4038 bytes result sent to driver
25/12/09 22:29:55 INFO CoarseGrainedExecutorBackend: Got assigned task 6
25/12/09 22:29:55 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)
25/12/09 22:29:55 INFO TorrentBroadcast: Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 1047.5 MiB)
25/12/09 22:29:55 INFO TorrentBroadcast: Reading broadcast variable 11 took 21 ms
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.6 KiB, free 1047.5 MiB)
25/12/09 22:29:55 INFO CodeGenerator: Code generated in 28.436327 ms
25/12/09 22:29:55 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:55 INFO TorrentBroadcast: Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1047.4 MiB)
25/12/09 22:29:55 INFO TorrentBroadcast: Reading broadcast variable 10 took 19 ms
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 380.9 KiB, free 1047.1 MiB)
25/12/09 22:29:55 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 1786 bytes result sent to driver
25/12/09 22:29:55 INFO CoarseGrainedExecutorBackend: Got assigned task 8
25/12/09 22:29:55 INFO Executor: Running task 0.0 in stage 11.0 (TID 8)
25/12/09 22:29:55 INFO MapOutputTrackerWorker: Updating epoch to 3 and clearing cache
25/12/09 22:29:55 INFO TorrentBroadcast: Started reading broadcast variable 14 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 1047.1 MiB)
25/12/09 22:29:55 INFO TorrentBroadcast: Reading broadcast variable 14 took 18 ms
25/12/09 22:29:55 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.8 KiB, free 1047.0 MiB)
25/12/09 22:29:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them
25/12/09 22:29:55 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@f91dceacf835:38263)
25/12/09 22:29:55 INFO MapOutputTrackerWorker: Got the map output locations
25/12/09 22:29:55 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 0 (0.0 B) local and 1 (88.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/12/09 22:29:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
25/12/09 22:29:55 INFO TransportClientFactory: Successfully created connection to spark-worker/172.19.0.7:41965 after 3 ms (0 ms spent in bootstraps)
25/12/09 22:29:55 INFO CodeGenerator: Code generated in 24.47149 ms
25/12/09 22:29:55 INFO Executor: Finished task 0.0 in stage 11.0 (TID 8). 4060 bytes result sent to driver
25/12/09 22:29:58 INFO CoarseGrainedExecutorBackend: Got assigned task 11
25/12/09 22:29:58 INFO Executor: Running task 0.0 in stage 15.0 (TID 11)
25/12/09 22:29:58 INFO MapOutputTrackerWorker: Updating epoch to 4 and clearing cache
25/12/09 22:29:58 INFO TorrentBroadcast: Started reading broadcast variable 19 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.8 MiB)
25/12/09 22:29:58 INFO TorrentBroadcast: Reading broadcast variable 19 took 17 ms
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 12.2 KiB, free 1048.8 MiB)
25/12/09 22:29:58 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 3, fetching them
25/12/09 22:29:58 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@f91dceacf835:38263)
25/12/09 22:29:58 INFO MapOutputTrackerWorker: Got the map output locations
25/12/09 22:29:58 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 0 (0.0 B) local and 1 (60.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/12/09 22:29:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/12/09 22:29:58 INFO Executor: Finished task 0.0 in stage 15.0 (TID 11). 4081 bytes result sent to driver
25/12/09 22:29:58 INFO CoarseGrainedExecutorBackend: Got assigned task 12
25/12/09 22:29:58 INFO Executor: Running task 0.0 in stage 16.0 (TID 12)
25/12/09 22:29:58 INFO TorrentBroadcast: Started reading broadcast variable 21 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 1048.8 MiB)
25/12/09 22:29:58 INFO TorrentBroadcast: Reading broadcast variable 21 took 15 ms
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 23.0 KiB, free 1048.8 MiB)
25/12/09 22:29:58 INFO CodeGenerator: Code generated in 27.166756 ms
25/12/09 22:29:58 INFO FileScanRDD: Reading File path: s3a://test/source/amounts_20251209_222937.json, range: 0-182, partition values: [empty row]
25/12/09 22:29:58 INFO TorrentBroadcast: Started reading broadcast variable 20 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 1048.7 MiB)
25/12/09 22:29:58 INFO TorrentBroadcast: Reading broadcast variable 20 took 14 ms
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 380.9 KiB, free 1048.3 MiB)
25/12/09 22:29:58 INFO Executor: Finished task 0.0 in stage 16.0 (TID 12). 1923 bytes result sent to driver
25/12/09 22:29:58 INFO CoarseGrainedExecutorBackend: Got assigned task 13
25/12/09 22:29:58 INFO Executor: Running task 0.0 in stage 18.0 (TID 13)
25/12/09 22:29:58 INFO MapOutputTrackerWorker: Updating epoch to 5 and clearing cache
25/12/09 22:29:58 INFO TorrentBroadcast: Started reading broadcast variable 22 with 1 pieces (estimated total size 4.0 MiB)
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 80.9 KiB, free 1048.3 MiB)
25/12/09 22:29:58 INFO TorrentBroadcast: Reading broadcast variable 22 took 16 ms
25/12/09 22:29:58 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 224.8 KiB, free 1048.0 MiB)
25/12/09 22:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/12/09 22:29:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/12/09 22:29:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/12/09 22:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/12/09 22:29:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/12/09 22:29:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/12/09 22:29:58 INFO CodecConfig: Compression: SNAPPY
25/12/09 22:29:58 INFO CodecConfig: Compression: SNAPPY
25/12/09 22:29:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
25/12/09 22:29:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "total_records",
    "type" : "long",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "total_amount",
    "type" : "long",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "average_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "max_amount",
    "type" : "long",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "min_amount",
    "type" : "long",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "report_date",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "report_time",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int64 total_records;
  optional int64 total_amount;
  optional double average_amount;
  optional int64 max_amount;
  optional int64 min_amount;
  required binary report_date (STRING);
  required binary report_time (STRING);
}

       
25/12/09 22:29:58 INFO CodecPool: Got brand-new compressor [.snappy]
25/12/09 22:29:59 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 4, fetching them
25/12/09 22:29:59 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@f91dceacf835:38263)
25/12/09 22:29:59 INFO MapOutputTrackerWorker: Got the map output locations
25/12/09 22:29:59 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/12/09 22:29:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/12/09 22:29:59 INFO CodeGenerator: Code generated in 29.908125 ms
25/12/09 22:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_202512092229581186180016137095195_0018_m_000000_13' to s3a://warehouse/reports/_temporary/0/task_202512092229581186180016137095195_0018_m_000000
25/12/09 22:29:59 INFO SparkHadoopMapRedUtil: attempt_202512092229581186180016137095195_0018_m_000000_13: Committed. Elapsed time: 120 ms.
25/12/09 22:29:59 INFO Executor: Finished task 0.0 in stage 18.0 (TID 13). 5017 bytes result sent to driver
25/12/09 22:29:59 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
25/12/09 22:29:59 INFO MemoryStore: MemoryStore cleared
25/12/09 22:29:59 INFO BlockManager: BlockManager stopped
25/12/09 22:29:59 ERROR CoarseGrainedExecutorBackend: RECE