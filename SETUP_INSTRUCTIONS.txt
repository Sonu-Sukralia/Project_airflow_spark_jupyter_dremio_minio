â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          DATA PLATFORM - SETUP INSTRUCTIONS                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ QUICK START (3 Steps):

1. Extract this archive:
   tar -xzf data-platform-complete.tar.gz
   cd data-platform

2. Start all services:
   docker-compose up -d

3. Wait 2-3 minutes, then access:
   â€¢ Airflow:  http://localhost:8085  (admin/admin)
   â€¢ Jupyter:  http://localhost:8888  (get token from logs)
   â€¢ Spark UI: http://localhost:9090
   â€¢ MinIO:    http://localhost:9001  (admin/password)

ğŸ“‹ REQUIREMENTS:
   âœ“ Docker & Docker Compose installed
   âœ“ 16GB RAM minimum
   âœ“ 50GB free disk space

ğŸ” GET JUPYTER TOKEN:
   docker-compose logs jupyter-spark | grep token

ğŸ“– FULL DOCUMENTATION:
   See README.md for complete details

ğŸ†˜ TROUBLESHOOTING:
   docker-compose logs -f [service-name]

ğŸ›‘ STOP SERVICES:
   docker-compose down

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

For detailed information, open README.md in a text editor.
